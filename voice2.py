import pandas as pd
from sklearn.preprocessing import LabelEncoder,StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.svm import SVC 
from sklearn.metrics import accuracy_score
import xgboost as xgb

#加载数据
df = pd.read_csv('./voice.csv')
#查看表的基本特征，展开省略号
pd.set_option('display.max_columns',1000)
print(df)
#查看缺失值
print(df.isnull().sum())
#查看大小
print(df.shape)
# 查看样本以及男女样本个数,df.label做一下筛选
print('样本个数：{}'.format(df.shape[0]))
print('男性个数：{}'.format(df[df.label=='male'].shape[0]))
print('女性个数：{}'.format(df[df.label=='female'].shape[0]))
#分离特征值与label
#对X  [:,:-1]不要最后一列  ,对y [:,-1]要最后一列
X = df.iloc[:,:-1]
y = df.iloc[:,-1]

#使用标签编码
gender_encoder = LabelEncoder()
y = gender_encoder.fit_transform(y)
print(y)
#进行标准化
scaler = StandardScaler()
X = scaler.fit_transform(X)
#切分数据集
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)

#使用SVC进行预测
svc = SVC()
svc.fit(X_train, y_train)
y_pred = svc.predict(X_test)
print('SVM 预测结果：',y_pred)
print('SVM 预测准确率：',accuracy_score(y_test,y_pred))

#换种方式求准确率
print('SVM 预测准确率：',svc.score(X_test,y_test))
#SVC中换线性核预测
svc = SVC(kernel='linear')
svc.fit(X_train, y_train)
y_pred = svc.predict(X_test)
print('linear SVM 预测结果：',y_pred)
print('linear SVM 预测准确率：',accuracy_score(y_test,y_pred))

#使用xgboost进行预测
param = {'boosting_type':'gbdt',
                         'objective' : 'binary:logistic', #任务目标
                         'eval_metric' : 'auc', #评估指标
                         'eta' : 0.01, #学习率
                         'max_depth' : 15, #树最大深度
                         'colsample_bytree':0.8, #设置在每次迭代中使用特征的比例
                         'subsample': 0.9, #样本采样比例
                         'subsample_freq': 8, #bagging的次数
                         'alpha': 0.6, #L1正则
                         'lambda': 0, #L2正则
}
#XGBoost无法解析带有标头的CSV文件，使用Xgboost自带的读取格式DMatrix()
train_data = xgb.DMatrix(X_train, y_train)
test_data = xgb.DMatrix(X_test, y_test)
#早停法，设2000次，如果37次结果没变化就停止
model = xgb.train(param, train_data,evals=[(train_data,'train'),(test_data,'valid')],num_boost_round=4000,early_stopping_rounds=37,verbose_eval=37)
y_pred = model.predict(test_data)
#将预测值做0，1处理
y_pred = [1 if x>=0.5 else 0 for x in y_pred]
print('xgboost 预测结果:',y_pred)
print('xgboost 预测准确率：',accuracy_score(y_test,y_pred))
#结果部分
"""zhangyuxi@ZhangdeMacBook-Pro voice % python3 voice2.py 
      meanfreq        sd    median       Q25       Q75       IQR       skew  \
0     0.059781  0.064241  0.032027  0.015071  0.090193  0.075122  12.863462   
1     0.066009  0.067310  0.040229  0.019414  0.092666  0.073252  22.423285   
2     0.077316  0.083829  0.036718  0.008701  0.131908  0.123207  30.757155   
3     0.151228  0.072111  0.158011  0.096582  0.207955  0.111374   1.232831   
4     0.135120  0.079146  0.124656  0.078720  0.206045  0.127325   1.101174   
...        ...       ...       ...       ...       ...       ...        ...   
3163  0.131884  0.084734  0.153707  0.049285  0.201144  0.151859   1.762129   
3164  0.116221  0.089221  0.076758  0.042718  0.204911  0.162193   0.693730   
3165  0.142056  0.095798  0.183731  0.033424  0.224360  0.190936   1.876502   
3166  0.143659  0.090628  0.184976  0.043508  0.219943  0.176435   1.591065   
3167  0.165509  0.092884  0.183044  0.070072  0.250827  0.180756   1.705029   

             kurt    sp.ent       sfm      mode  centroid   meanfun    minfun  \
0      274.402906  0.893369  0.491918  0.000000  0.059781  0.084279  0.015702   
1      634.613855  0.892193  0.513724  0.000000  0.066009  0.107937  0.015826   
2     1024.927705  0.846389  0.478905  0.000000  0.077316  0.098706  0.015656   
3        4.177296  0.963322  0.727232  0.083878  0.151228  0.088965  0.017798   
4        4.333713  0.971955  0.783568  0.104261  0.135120  0.106398  0.016931   
...           ...       ...       ...       ...       ...       ...       ...   
3163     6.630383  0.962934  0.763182  0.200836  0.131884  0.182790  0.083770   
3164     2.503954  0.960716  0.709570  0.013683  0.116221  0.188980  0.034409   
3165     6.604509  0.946854  0.654196  0.008006  0.142056  0.209918  0.039506   
3166     5.388298  0.950436  0.675470  0.212202  0.143659  0.172375  0.034483   
3167     5.769115  0.938829  0.601529  0.267702  0.165509  0.185607  0.062257   

        maxfun   meandom    mindom    maxdom   dfrange   modindx   label  
0     0.275862  0.007812  0.007812  0.007812  0.000000  0.000000    male  
1     0.250000  0.009014  0.007812  0.054688  0.046875  0.052632    male  
2     0.271186  0.007990  0.007812  0.015625  0.007812  0.046512    male  
3     0.250000  0.201497  0.007812  0.562500  0.554688  0.247119    male  
4     0.266667  0.712812  0.007812  5.484375  5.476562  0.208274    male  
...        ...       ...       ...       ...       ...       ...     ...  
3163  0.262295  0.832899  0.007812  4.210938  4.203125  0.161929  female  
3164  0.275862  0.909856  0.039062  3.679688  3.640625  0.277897  female  
3165  0.275862  0.494271  0.007812  2.937500  2.929688  0.194759  female  
3166  0.250000  0.791360  0.007812  3.593750  3.585938  0.311002  female  
3167  0.271186  0.227022  0.007812  0.554688  0.546875  0.350000  female  

[3168 rows x 21 columns]
meanfreq    0
sd          0
median      0
Q25         0
Q75         0
IQR         0
skew        0
kurt        0
sp.ent      0
sfm         0
mode        0
centroid    0
meanfun     0
minfun      0
maxfun      0
meandom     0
mindom      0
maxdom      0
dfrange     0
modindx     0
label       0
dtype: int64
(3168, 21)
样本个数：3168
男性个数：1584
女性个数：1584
[1 1 1 ... 0 0 0]
/usr/local/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.
  "avoid this warning.", FutureWarning)
SVM 预测结果： [0 1 0 1 0 0 0 1 1 0 0 0 0 0 1 0 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 0 0 1 0 0 0
 1 1 1 0 0 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 0 1 0 0 0 1 0 0 1 0 0 0 1 0 0
 0 1 1 1 0 1 0 1 1 1 0 1 1 1 0 1 0 0 1 1 0 1 0 0 1 0 1 0 1 1 0 1 0 0 1 0 1
 1 0 0 0 1 1 1 0 0 1 0 1 1 1 0 1 0 0 1 0 0 1 0 0 1 0 0 1 1 0 1 1 1 1 1 1 1
 1 1 0 0 0 0 0 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 1 0 0 1 0 0 0 0 0 1 1 1 0 1 1
 1 0 1 1 1 0 0 1 0 0 1 1 1 0 1 0 0 1 1 1 1 1 1 0 0 0 1 1 1 1 1 0 1 0 0 1 0
 1 0 1 0 0 0 0 0 1 0 0 0 1 1 1 0 1 0 1 0 0 0 0 1 1 0 0 1 0 0 0 0 1 0 1 0 0
 0 0 0 1 0 0 0 0 1 1 0 1 0 1 0 1 1 0 1 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0
 1 0 0 0 1 0 0 1 1 1 0 0 0 0 1 0 0 0 1 0 0 1 0 0 1 0 0 0 1 0 0 1 1 1 1 1 0
 0 1 0 0 1 0 1 1 1 0 1 1 1 0 0 1 0 0 0 0 0 1 1 0 0 0 1 0 1 1 0 1 0 1 1 0 0
 1 0 1 0 0 0 0 1 1 1 1 1 0 1 1 1 0 1 1 1 0 0 0 1 0 0 1 1 1 1 0 1 1 1 0 1 0
 0 1 0 1 0 1 0 1 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 1 1 0 0 0 1
 0 1 1 0 0 1 0 1 0 1 0 0 1 0 0 1 1 1 0 0 0 0 1 0 0 1 0 1 1 1 0 1 0 1 0 0 1
 1 0 0 0 1 1 1 0 1 0 1 0 0 0 0 1 1 1 1 0 0 1 1 1 1 0 1 1 1 0 1 1 1 0 0 0 0
 1 0 1 0 1 1 0 0 1 0 1 0 1 0 0 1 0 1 1 1 1 0 1 0 0 0 0 1 0 0 1 0 0 1 0 1 1
 0 1 1 1 0 0 0 0 0 1 1 1 0 1 1 0 1 0 0 0 1 0 1 0 1 1 0 0 1 1 0 1 1 1 1 0 0
 0 1 1 0 0 1 1 1 0 1 0 0 0 1 0 0 1 1 0 1 1 1 0 1 0 1 1 1 1 1 0 1 0 0 1 0 1
 1 0 1 0 0]
SVM 预测准确率： 0.9889589905362776
SVM 预测准确率： 0.9889589905362776
linear SVM 预测结果： [1 1 1 0 1 1 0 1 0 0 1 0 1 1 0 1 0 1 0 1 0 1 0 0 0 1 0 0 1 0 1 0 1 0 0 1 0
 0 0 1 1 1 1 0 0 1 0 0 1 0 0 0 0 0 0 1 0 1 0 0 1 1 0 1 1 1 0 0 0 0 1 0 0 0
 0 0 0 1 1 0 0 1 1 1 0 1 0 0 0 0 1 1 1 0 1 0 1 0 0 1 0 1 0 0 1 0 0 0 1 1 0
 0 1 1 1 0 1 0 1 0 1 0 1 1 1 0 1 0 0 0 1 1 1 1 1 1 0 0 0 0 1 0 1 1 0 0 1 0
 0 1 1 1 1 1 0 1 0 1 0 1 0 1 0 0 1 1 0 0 0 1 1 1 0 1 1 1 1 1 1 1 0 1 1 0 1
 1 1 0 1 0 0 1 0 1 1 0 0 0 1 1 0 0 0 1 1 0 0 0 1 1 0 0 0 1 0 0 0 1 1 0 0 1
 1 0 1 0 0 1 0 1 0 1 0 1 1 1 1 1 0 0 1 1 1 1 0 0 1 0 0 0 0 1 0 1 0 0 0 0 1
 1 1 1 1 1 0 1 0 1 1 1 0 1 0 0 1 1 1 0 1 0 1 1 1 1 0 1 1 1 1 0 1 1 0 0 1 1
 0 0 1 0 0 1 0 1 0 0 0 1 0 0 1 0 1 0 0 1 0 1 0 1 0 1 1 1 0 0 1 0 1 1 0 0 1
 1 0 1 0 1 1 1 1 1 1 1 1 0 0 1 1 0 0 1 1 1 1 1 0 0 1 1 1 0 1 0 1 0 0 0 0 1
 0 1 0 1 1 1 1 1 1 0 1 1 0 1 1 1 1 0 1 1 0 0 1 1 0 1 1 0 0 1 0 1 1 1 1 0 0
 1 1 0 1 0 1 1 1 0 0 0 0 0 0 1 0 0 1 0 1 0 1 0 1 1 0 1 0 1 0 0 1 1 0 1 0 1
 0 0 1 1 1 1 1 0 1 1 1 0 0 0 1 1 0 0 1 0 1 0 0 1 0 1 1 1 0 1 1 1 0 1 1 0 0
 1 0 1 0 0 0 1 1 1 1 1 1 0 0 1 1 0 0 0 0 1 0 1 0 1 0 1 1 1 1 1 0 1 0 1 0 1
 1 1 1 0 1 0 1 1 1 0 1 0 1 0 1 1 0 1 0 1 1 0 1 1 1 1 1 0 1 0 0 1 0 1 0 0 1
 0 0 0 0 0 1 1 1 1 0 1 0 1 1 1 0 1 0 1 0 1 1 1 1 0 0 1 1 0 1 1 0 0 0 0 1 1
 0 0 0 0 0 1 0 0 1 0 0 1 1 0 1 1 1 0 0 0 0 1 0 1 0 0 1 0 0 0 1 1 0 0 0 1 1
 0 1 0 0 1]
linear SVM 预测准确率： 0.9842271293375394
[17:15:11] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: 
Parameters: { boosting_type, subsample_freq } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[0]	train-auc:0.99152	valid-auc:0.99037
Multiple eval metrics have been passed: 'valid-auc' will be used for early stopping.

Will train until valid-auc hasn't improved in 37 rounds.
[37]	train-auc:0.99941	valid-auc:0.99657
[74]	train-auc:0.99960	valid-auc:0.99715
[111]	train-auc:0.99969	valid-auc:0.99704
Stopping. Best iteration:
[74]	train-auc:0.99960	valid-auc:0.99715

xgboost 预测结果: [1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1]
xgboost 预测准确率： 0.9826498422712934
"""
